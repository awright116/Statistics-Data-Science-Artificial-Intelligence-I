{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "977e85cb-cb73-4f69-96bb-08caea6cb95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  [[2 1]\n",
      " [1 1]]\n",
      "b:  [ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the quadratic function in terms of x1 and x2\n",
    "def f(x1, x2):\n",
    "    return  2*x1^2 + 2*x1*x2 + x2^2 + x1 - x2\n",
    "\n",
    "def f_x(x1, x2):\n",
    "    return 1/2 * (Q11*x1**2 + 2*Q12*x1*x2 + Q22*x2**2) + b1*x1 - b2*x2\n",
    "\n",
    "def compute_f():\n",
    "    x = np.array([1, 1])\n",
    "    x_T = np.array([[1],\n",
    "                [1]])\n",
    "    \n",
    "    Q11 = 4\n",
    "    Q12 = 1\n",
    "    Q21 = 1\n",
    "    Q22 = 2\n",
    "    Q = np.array([[Q11, Q12], [Q21, Q22]])\n",
    "    \n",
    "    b1 = 1\n",
    "    b2 = -1\n",
    "    b = np.array([b1, b2])\n",
    "    return Q, b\n",
    "\n",
    "Q, b = compute_f()\n",
    "\n",
    "print(\"Q: \", Q)\n",
    "print(\"b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a69eee-4a13-4bf1-8b81-8fcfb8bb30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter x1 value:  1\n",
      "Enter x2 value:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 3.]\n",
      "Q:  [[4 1]\n",
      " [1 2]]\n",
      "b:  [ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x1 = float(input(\"Enter x1 value: \")) # user x1 value\n",
    "x2 = float(input(\"Enter x2 value: \")) # user x2 value\n",
    "\n",
    "def f(x1,x2):\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "    \n",
    "def gradient_f(x1,x2): \n",
    "    return np.array([4 * x1 + 2 * x2 + 1, 2 * x1 + 2 * x2 -1])\n",
    "\n",
    "def compute_f():\n",
    "    x = np.array([1, 1])\n",
    "    x_T = np.array([[1],\n",
    "                [1]])\n",
    "    \n",
    "    Q11 = 4\n",
    "    Q12 = 1\n",
    "    Q21 = 1\n",
    "    Q22 = 2\n",
    "    Q = np.array([[Q11, Q12], [Q21, Q22]])\n",
    "    \n",
    "    b1 = 1\n",
    "    b2 = -1\n",
    "    b = np.array([b1, b2])\n",
    "    return Q, b\n",
    "\n",
    "Q, b = compute_f()\n",
    "\n",
    "print(gradient_f(x1,x2))\n",
    "print(\"Q: \", Q)\n",
    "print(\"b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "836f24a4-6315-495d-92fd-6d191469014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter x1 value:  1\n",
      "Enter x2 value:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 5.]\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.3\n",
    "import numpy as np\n",
    "\n",
    "x1 = float(input(\"Enter x1 value: \")) # user x1 value\n",
    "x2 = float(input(\"Enter x2 value: \")) # user x2 value\n",
    "\n",
    "def f(x1,x2):\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "    \n",
    "def gradient_f(x1,x2): \n",
    "    return np.array([4 * x1 + 2 * x2 + 1, 2 * x1 + 2 * x2 -])\n",
    "\n",
    "print(gradient_f(x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76c367d-32fd-42c0-97f0-f77a4ac2b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [-1.          1.49999999]\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.4\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy.optimize as spo\n",
    "\n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "\n",
    "def gradient_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = 4 * x1 + 2 * x2 + 1\n",
    "    df_dx2 = 2 * x1 + 2 * x2 - 1\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "\n",
    "def hessian_f(x):\n",
    "    return np.array([[4, 2], [2, 2]])\n",
    "\n",
    "def steepestdescent(f,gradient_f,x0,tol=1.e-3,maxit=50):\n",
    "    x = x0\n",
    "    r = df(x0)\n",
    "    iters = 0\n",
    "\n",
    "def gd(lambda_k,x,r):\n",
    "    return f(x - lambda_k*r)\n",
    "    \n",
    "def steepestdescent(f,df,x0,tol=1.e-3,maxit=50):\n",
    "    x = x0\n",
    "    r = df(x0)\n",
    "    iters = 0\n",
    "    while ( np.abs(npl.norm(r))>tol and iters<maxit ):\n",
    "        lambda_k = spo.golden(g,(x,r))\n",
    "        x = x - lambda_k * r\n",
    "        r = df(x)\n",
    "        iters += 1\n",
    "    return x\n",
    "    \n",
    "x0 = np.array([2.0,1.0])\n",
    "x=steepestdescent(f, gradient_f, x0, tol = 1.e-8, maxit = 50)\n",
    "print('x = ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55071a53-c869-47fd-afd8-c4c94599912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizer x: [-1.          1.49999999]\n",
      "Number of iterations: 19\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.4\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy.optimize as spo\n",
    "\n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "\n",
    "def gradient_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = 4 * x1 + 2 * x2 + 1\n",
    "    df_dx2 = 2 * x1 + 2 * x2 - 1\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "    \n",
    "def g(lambda_k,x,r):\n",
    "    return f(x - lambda_k*r)\n",
    "\n",
    "def exact_line(f, gradient_f, x0, tol=1.e-8, maxit=100):\n",
    "    x = np.array(x0)\n",
    "    r = gradient_f(x)\n",
    "    k = 0\n",
    "    while np.abs(npl.norm(r)) > tol and k < maxit:\n",
    "        lambda_k = spo.golden(lambda l: g(l, x, r))\n",
    "        x = x - lambda_k * r\n",
    "        r = gradient_f(x)\n",
    "        k += 1\n",
    "    return x, k\n",
    "\n",
    "\n",
    "x0 = np.array([4.0, 2.0])\n",
    "solution, num_iterations = exact_line(f, gradient_f, x0, tol=1.e-8, maxit=50)\n",
    "\n",
    "print('Minimizer x:', solution)\n",
    "print('Number of iterations:', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ce17924-2c3f-42aa-b78c-ee09b7ac2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizer x: [-0.99999997  1.49999994]\n",
      "Number of iterations: 105\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.5\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy.optimize as spo\n",
    "\n",
    "def g(lambda_k,x,r):\n",
    "    return f(x - lambda_k*r)\n",
    "\n",
    "def fixed_step(f, gradient_f, x0, tol=1.e-6, maxit=100):\n",
    "    step = [x0]\n",
    "    x = x0\n",
    "    r = gradient_f(x)\n",
    "    lambda_k = 0.2\n",
    "    \n",
    "    for i in range(maxit):\n",
    "        diff = lambda_k * r\n",
    "        if npl.norm(diff)<tol:\n",
    "            break\n",
    "        x = x - diff\n",
    "        r = gradient_f(x)\n",
    "        step.append(x) ## tracking\n",
    "    return step, i + 1\n",
    "    \n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "\n",
    "def gradient_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = 4 * x1 + 2 * x2 + 1\n",
    "    df_dx2 = 2 * x1 + 2 * x2 - 1\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "x0 = np.array([2.0, 1.0])\n",
    "solution, num_iterations = fixed_step(f, gradient_f, x0, tol=1.e-8, maxit=200)\n",
    "\n",
    "print('Minimizer x:', solution[-1])\n",
    "print('Number of iterations:', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b05c564f-469a-49a6-a055-004e7a3abc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizer x: [-1.   1.5]\n",
      "Number of iterations: 61\n"
     ]
    }
   ],
   "source": [
    "#Problem 1.6\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "import scipy.optimize as spo\n",
    "\n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return 2 * x1**2 + 2 * x1 * x2 + x2**2 + x1 - x2\n",
    "\n",
    "def gradient_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = 4 * x1 + 2 * x2 + 1\n",
    "    df_dx2 = 2 * x1 + 2 * x2 - 1\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "def step_size(f, gradient_f, x):\n",
    "    alpha = 1.0\n",
    "    beta = 0.8\n",
    "    r = gradient_f(x)\n",
    "    while f(x - alpha*r) > (f(x) - 0.5*alpha*lp.norm(r)**2):\n",
    "        alpha *= beta\n",
    "    return alpha\n",
    "\n",
    "def g(lambda_k,x,r):\n",
    "    return f(x - lambda_k*r)\n",
    "\n",
    "def back_track(f, gradient_f, x0, tol=1.e-8, maxit=100):\n",
    "    x = np.array(x0)\n",
    "    r = gradient_f(x)\n",
    "    k = 0\n",
    "    while npl.norm(r) > tol and k < maxit:\n",
    "        lambda_k = step_size(f, gradient_f, x)\n",
    "        x = x - lambda_k * r\n",
    "        r = gradient_f(x)\n",
    "        k += 1\n",
    "    return x, k\n",
    "\n",
    "x0 = np.array([2.0,1.0])\n",
    "\n",
    "x, num_iterations = back_track(f, gradient_f, x0, tol=1.e-8, maxit=200)\n",
    "\n",
    "print('Minimizer x:', x)\n",
    "print('Number of iterations:', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d72a282f-c27e-4e01-9a6e-c88a67683517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.26666667] [46.16666667]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2.1\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "\n",
    "B_0 = 0\n",
    "B_1 = 0\n",
    "\n",
    "def grad_beta(x, y, B_0, B_1):\n",
    "    n = len(y)\n",
    "    residuals = (y - (B_0 + (B_1 * x)))\n",
    "    \n",
    "    df_yint = (1/n) * np.sum(residuals)\n",
    "    df_slope = (1/n) * np.sum((residuals) * x)\n",
    "    g_B = np.array([[df_yint],\n",
    "               [df_slope]])\n",
    "    return g_B\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([5.0, 6.0, 7.0])\n",
    "\n",
    "df_yint, df_slope = grad_beta(x, y, B_0, B_1)\n",
    "\n",
    "print(df_yint, df_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "34722d2e-2ebc-4b06-8edb-51afac54e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14377533 1.23371695]\n",
      "Iiterations: 200\n"
     ]
    }
   ],
   "source": [
    "# Problem 2.2\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "\n",
    "def grad_beta(x, y, B_0, B_1):\n",
    "    n = len(y)\n",
    "    residuals = (y - (B_0 + (B_1 * x))) \n",
    "    \n",
    "    df_yint = -(1 / n) * np.sum(residuals)  \n",
    "    df_slope = -(1 / n) * np.sum(residuals * x)  \n",
    "    \n",
    "    g_B = np.array([df_yint, df_slope])\n",
    "    return g_B\n",
    "\n",
    "def gradient_descent_fixed_step(x, y, B_0_init, B_1_init, lambda_k, tol=1e-8, maxit=200):\n",
    "    B = np.array([B_0_init, B_1_init])\n",
    "    steps = [B.copy()] \n",
    "    k = 0 \n",
    "    \n",
    "    for _ in range(maxit):\n",
    "        gradient = grad_beta(x, y, B[0], B[1]) \n",
    "        B_new = B - lambda_k * gradient\n",
    "        \n",
    "        steps.append(B_new.copy())  \n",
    "        \n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            break\n",
    "        \n",
    "        B = B_new  \n",
    "        k += 1\n",
    "    \n",
    "    return B, k\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([5.0, 6.0, 7.0])\n",
    "\n",
    "B_0_init = 0.0\n",
    "B_1_init = 0.0\n",
    "\n",
    "lambda_k = 0.001\n",
    "\n",
    "\n",
    "B_final, num_iterations = gradient_descent_fixed_step(x, y, B_0_init, B_1_init, lambda_k)\n",
    "\n",
    "\n",
    "print(B_final)\n",
    "print(f\"Iiterations: {num_iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "85a3b2d3-c557-49b2-acc6-fe463e5deeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.53676604  1.6580232 ]\n",
      "Iterations: 200\n"
     ]
    }
   ],
   "source": [
    "# Problem 2.3 \n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "\n",
    "def grad_beta(x, y, B_0, B_1):\n",
    "    n = len(y)\n",
    "    residuals = y - (B_0 + B_1 * x[:, 1])\n",
    "    df_yint = -(1 / n) * np.sum(residuals)\n",
    "    df_slope = -(1 / n) * np.sum(residuals * x[:, 1])\n",
    "    g_B = np.array([df_yint, df_slope])\n",
    "    return g_B\n",
    "\n",
    "def backtracking_line_search(x, y, B, grad, alpha=0.2, beta=0.8):\n",
    "    t = alpha\n",
    "    while True:\n",
    "        B_new = B - t * grad\n",
    "        y_pred_new = x @ B_new\n",
    "        y_pred = x @ B\n",
    "        lhs = np.sum((y - y_pred_new) ** 2)\n",
    "        rhs = np.sum((y - y_pred) ** 2) - 0.5 * t * np.sum(grad ** 2)\n",
    "        if lhs <= rhs:\n",
    "            break\n",
    "        t *= beta\n",
    "    return t\n",
    "    \n",
    "def gradient_descent_backtracking(x, y, B_0_init, B_1_init, tol=1e-6, maxit=200):\n",
    "    B = np.array([B_0_init, B_1_init])\n",
    "    step = [B.copy()]\n",
    "    k = 0\n",
    "\n",
    "    for _ in range(maxit):\n",
    "        gradient = grad_beta(x, y, B[0], B[1])\n",
    "        lambda_k = backtracking_line_search(x, y, B, gradient)\n",
    "        B_new = B - lambda_k * gradient\n",
    "\n",
    "        step.append(B_new.copy())\n",
    "\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            break\n",
    "\n",
    "        B = B_new\n",
    "        k += 1\n",
    "\n",
    "    return B, k\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([[1, 5.0],\n",
    "              [1, 6.0],\n",
    "              [1, 7.0]])\n",
    "\n",
    "B_0_init = 0.0\n",
    "B_1_init = 0.0\n",
    "\n",
    "B_final, num_iterations = gradient_descent_backtracking(x, y, B_0_init, B_1_init)\n",
    "\n",
    "print(B_final)\n",
    "print(f\"Iterations: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ae39dc99-5c47-4a48-a93f-3d9f13304f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: [ 7.26666667 46.16666667]\n"
     ]
    }
   ],
   "source": [
    "# Problem 3.1\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "\n",
    "def grad_beta(x, y, B):\n",
    "    n = len(y)\n",
    "    e = y - np.dot(x, B)  # Residuals\n",
    "    g_B = (1 / n) * np.dot(x.T, e)  # Gradient\n",
    "    return g_B\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([[1, 5.0],\n",
    "              [1, 6.0],\n",
    "              [1, 7.0]])\n",
    "\n",
    "b_init = np.array([0.0, 0.0])\n",
    "\n",
    "gradient = grad_beta(x, y, b_init)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "90bcb3c3-7638-42f7-805d-0de6f039c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.831477290301448 3.8496961371229594\n",
      "Iterations: 17058\n"
     ]
    }
   ],
   "source": [
    "# Problem 3.2\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "\n",
    "def grad_beta(x, y, B):\n",
    "    n = len(y)\n",
    "    e = y - np.dot(x, B) \n",
    "    g_B = -(1 / n) * np.dot(x.T, e) \n",
    "    return g_B\n",
    "\n",
    "def gradient_descent_fixed_step(x, y, B_init, lambda_k, tol=1e-6, maxit=10000):\n",
    "    B = B_init.copy()\n",
    "    steps = [B.copy()]\n",
    "    \n",
    "    for i in range(maxit):\n",
    "        gradient = grad_beta(x, y, B)\n",
    "        B_new = B - lambda_k * gradient\n",
    "        steps.append(B_new.copy())\n",
    "        \n",
    "        if np.linalg.norm(B_new - B) < tol:\n",
    "            break\n",
    "        \n",
    "        B = B_new\n",
    "    \n",
    "    return steps, i + 1\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([[1, 5.0],\n",
    "              [1, 6.0],\n",
    "              [1, 7.0]])\n",
    "\n",
    "B_init = np.array([0.0, 0.0])\n",
    "lambda_k = 0.03\n",
    "tol = 1e-6\n",
    "maxit = 100000\n",
    "\n",
    "steps, num_iterations = gradient_descent_fixed_step(x, y, B_init, lambda_k, tol, maxit)\n",
    "\n",
    "B_final = steps[-1]\n",
    "print(B_final[0], B_final[1])\n",
    "print(f\"Iterations: {num_iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e75a206a-3d8e-4b98-a249-c50dd61215a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.005953835866152757 1.2589017772030977\n",
      "Iterations: 18\n"
     ]
    }
   ],
   "source": [
    "# Problem 3.3\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "from numpy import linalg as lp\n",
    "\n",
    "def grad_beta(x, y, B):\n",
    "    n = len(y)\n",
    "    e = y - np.dot(x, B)\n",
    "    return -(1 / n) * np.dot(x.T, e)\n",
    "\n",
    "def backtracking_line_search(x, y, B, gradient, alpha=0.5, beta=0.8):\n",
    "    t = 1.0\n",
    "    while np.linalg.norm(grad_beta(x, y, B - t * gradient)) > (1 - alpha * t) * np.linalg.norm(gradient):\n",
    "        t *= beta\n",
    "    return t\n",
    "\n",
    "def gradient_descent_backtracking(x, y, B_init, tol=1e-6, max_iter=10000):\n",
    "    B = B_init.copy()\n",
    "    steps = [B.copy()]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        gradient = grad_beta(x, y, B)\n",
    "        step_size = backtracking_line_search(x, y, B, gradient)\n",
    "        B_new = B - step_size * gradient\n",
    "        steps.append(B_new.copy())\n",
    "        \n",
    "        if np.linalg.norm(B_new - B) < tol:\n",
    "            break\n",
    "        \n",
    "        B = B_new\n",
    "    \n",
    "    return steps, i + 1\n",
    "\n",
    "\n",
    "y = np.array([3.8, 6.5, 11.5])\n",
    "x = np.array([[1, 5.0],\n",
    "              [1, 6.0],\n",
    "              [1, 7.0]])\n",
    "B_init = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "steps, num_iterations = gradient_descent_backtracking(x, y, B_init)\n",
    "B_final = steps[-1]\n",
    "\n",
    "print(B_final[0], B_final[1])\n",
    "print(f\"Iterations: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba275948-a3e7-46e9-9b38-10320a4623dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
